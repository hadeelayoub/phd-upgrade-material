\chapter{Methodology}

\section{Research Methods}\label{chap:researchmethods}

Human-problem oriented inventions \parencite{Cox2008} , similar to my proposed design of the data glove, have conventionally employed user-centred design research methods \parencite{Bevan1999}. Rather than starting with an idea for a system based on what technology can do, and then trying to determine whether people will be able and willing to use it, instead I will start with people's needs and ability; and find a technology that they will be able to use to fulfil a need. This strategy is confirmed in multiple research resources in HCI \parencite{Dix2004} and is referred to as ‘Interaction Design’.

The main steps in such a strategy are the following: 

\begin{enumerate}
    \item Identify a problem that requires a solution, which then becomes the research goal. This can be confirmed through surveys, interviews and observation. 
    \item Find the source of the problem. What is causing the difficulty?
    \item Invent a solution to help people with their difficulty. This can be done through multiple rounds of testing and developing to prove that the proposed solution is valid. Interaction design research will be used in this phase to develop and test iterations of the designed system, in a build-measure-learn loop.
    \item Create a system which incorporates findings and make it available to the people who struggled with the previously identified problem. If the function people wanted to perform but couldn't do well is made more available, chances are it will be successful, considering of course it is affordable, which is a major consideration in this research.
\end{enumerate}

For the theoretical part of my research, Grounded theory will be employed, where theory emerges from the collected data which will be gained through multiple rounds of data collection. Interaction design method will then be applied to use the collected data to prove the theory through a series of usability studies which will mainly constitute of demonstration case studies followed by longitudinal \& In-depth case studies. This will be discussed in detail in the evaluation chapter.
I propose combining Grounded Theory with Interaction Design Research, to structure the iterative design phase of Grounded Theory. I chose Interaction Research because it is more of a holistic approach to problem-solving, rather than a single method for collecting and analysing data \parencite{OBrienRoryFacultyofInformationStudies2001}. In conjunction with this, user-centred design usability testing will then be used to validate the proposed solution for the identified problem. 

\subsection{Grounded Theory} 

Grounded Theory started as the analysis of qualitative research data. However, it was later identified as ``a method of qualitative research that aims to produce new theories that are grounded in the qualitative data gathered during the research''  \parencite{Glaser1967}.
Researchers Strauss and Corbin \parencite{Strauss1990} used the term ``Grounded Theory'' to refer to a theory building approach based on an analysis technique they formulated of collected data that can incorporate both qualitative data sets such as interviews, focus groups, observations and ethnographic studies and quantitative data sets such as questionnaires, logs and experimental data. ``The research findings constitute a theoretical formulation of the reality under investigation, rather than consisting of a set of numbers, or a group of loosely related themes'' \parencite {Strauss1990}.

Grounded theory is different from other research methods in that it does not require a prior hypothesis before conducting research \parencite{Glaser1967}. Researchers may approach the research with an identified goal without knowing what they expect to find \parencite{Adams1997}. ``The process of doing the research formulates the theory and therefore produces potential hypotheses for further study'' \parencite{Adams1997}. A side-effect of this is that research data previously collected on the same phenomena can be used for further research.

In Grounded Theory, the theory is developed once there is available data to analyse and not once the data collection phase is concluded. A good example is the first interview, although one interview is not sufficient to base a theory on, it is however a good indication of validating and expanding the theory and leads to a tentative theory \parencite{Cox2008}.
In subsequent interviews, the researcher would design the questions with the intention of testing the limits of the theory. The second interview analysis would either confirm or reject the theory. It may even produce a new theory and so on. ``Thus, the method proceeds through cycles of data gathering, analysis and theorizing'' \parencite{Cox2008}. As a result, interview questions progress from the initial interview and are generated based on the results of each cycle of interviews. Questions can be very different later in the study than the very first interview. This approach is applied to different data collection methods throughout the study where the reliability of the method is tested through ``systematic repetition of observations in quantitative research'' \parencite{Strauss1990}.
Strauss and Corbin \parencite{Strauss2008} suggest that grounded theory is especially useful for complex subjects or phenomena where little is yet known. This is a major reason why I have chosen it as the main research method for conducting this research. ``The methodology's flexibility can cope with complex data and its continual cross-referencing allows uncovering previously unknown issues'' \parencite{Strauss2008} and grounding of the theory specifically to validate the proposed solution for the identified. Emphasis is placed on theoretical sampling and contextual considerations so that later transferability of finding can be increased. 
This is useful for new emerging fields of research relevant to innovation and assistive technology. 
The collected data is analysed in a standard grounded theory format. It is then broken down, conceptualized and put back together in new ways. To enable this to occur in a structured manner, Strauss and Corbin \parencite{Strauss2008} have devised three major bonding stages – ``open, axial and selective'' \parencite{Strauss2008} - in the analysis procedure. The lines between these forms of coding are artificial, as is the division between data collection and analysis.  This is an analytic distinction, but in practice, all of these elements of grounded theory analysis intersect as the interpretation proceeds.

Coding categories in my research as identified in the research question are:
\begin{itemize}
    \item \textbf{Assistive:} Effective in facilitating daily communication between sign language users and the public. This specifically measures the performance of the glove, its durability and comfort and mobility.
    \item \textbf{Universal:} Can be used by adults (all genders), children, output different languages, compatible with any platform, translate different libraries of sign language including customized gestures.
    \item \textbf{Accessible:} Can be made available to people who need it, not requiring any external hardware or device, stand alone, wireless.
    \item \textbf{Affordable:} Cost effective – reasonably priced.
\end{itemize}

The reason I chose to pair grounded theory with interaction design research as my proposed research methodology is because both grounded theory and interaction design research methods employ an ``interplay between data collection and data analysis, which results in the concepts and theory truly emerging from the data'' \parencite{Lazar2010}. In this approach, detailed and through coding is conducted from the multiple rounds of data collection. Results depends on researchers listening to the data. As in most research in the HCI field, both text-based information and multimedia-based information will be collected from the participants \parencite{Lazar2010}. 
However, since I will be designing new technology and studying speech-based interaction, I will also need to evaluate a number of issues relating to the recognition rate, which requires comparison between the recorded data and the system output. 
This leads me to the description of kinds of methodology that bear on the invention of new computer-based methods \parencite{Rogers2011} and to be combined with the coding criteria for grounded theory, specifically to evaluate system performance: 

Failure Analysis: is to find out specifically where things go wrong. 
Individual Difference Analysis: This is to identify that certain kinds of users, ones with certain background characteristics or abilities, affect the results of testing the system in different ways. This is directly relevant to my proposed universal design of a sign language data glove to be used by all ages, genders, languages and abilities. 
Time Profiling: Time profiling is used to measure and analysing how much time Is spent on isolated tasks within the system. Time profiling is important in identifying problems in the system and potential areas for improvement \parencite{Cox2008}. 

\subsection{Interaction Design Research: build - measure - learn}

Referring to multiple resources on research methods in HCI \parencite{Cox2008}  \parencite{Dix2004}  \parencite{Lazar2010}  \parencite{Zimmerman:2007:RTD:1240624.1240704}, I have identified the practice portion of my PhD proposal as interaction design. The start and focus of any interaction design is the intended user or users \parencite{Dix2004}. The user in my case is speech disabled individuals who use sign language for their daily communication. My research, design and evaluation will be based on their needs. Consequently, testing rounds will employ user-centred design research methods.

In principle, interaction design research is ``learning by doing'': researchers identify a problem, design a solution, test and evaluate their proposal, and if not satisfied, try again using the feedback they gained from the research cycle.  While this is the essence of the approach, there are other key attributes of interaction design research that differentiate it from other problem-solving research methods. One being its emphasis is on scientific study. In interaction design research, the problem is studied systematically, and intervention is informed by theoretical considerations, which in my case will be the outcome of grounded theory research.  In Interaction design research, data is presented on an ongoing basis. All the while, the methodological tools are being refined to suit the demands of the research \parencite{OBrienRoryFacultyofInformationStudies2001}. 
 
Another reason that I chose Interaction design research, is because it is a user-cantered research methodology. Interaction design research focuses on turning the people involved in the studies and testing into researchers, too. ``People learn best, and more willingly apply what they have learned, when they do it themselves.  It also has a social dimension - the research takes place in real-world situations, and aims to solve real problems'' \parencite{OBrienRoryFacultyofInformationStudies2001}. This is the exact setting for my research studies, where real participants will test and use the data glove, sometimes over a long period of time and mostly in their own environments.
The interaction design process \parencite{Dix2004} of the research will be divided into four main phases plus an iteration loop (feeds evaluations back into the deign), focused on the design of interaction, illustrated in Figure \ref{fig:idpdiagram}.

\begin{figure} 
    \centering
    \begin{tikzpicture}[node distance=1em, >=stealth', bend angle=45, auto, every node/.style={scale=0.7}]
    
        \tikzstyle{place}=[rectangle, rounded corners, thick, draw=blue!22, fill=blue!20, minimum width=5em]
        
        \tikzstyle{every label}=[red]
        
        \begin{scope}
            \node [place] (id)								{Identify a Problem};
            \node [place] (an) [right=of id]               	{Analysis};
            \node [place] (de) [right=of an, yshift=3em]	{Design a Solution};
            \node [place] (pr) [below=of de, yshift=-3em]   	{Prototype};
            \node [place] (ev) [right=of de, yshift=-3em]           		{Test \& Evaluate};
            \node [place] (im) [right=of ev]               	{Implement \& Deploy};
            
            \path (id) edge[->] (an);
            \path (an) edge[->, bend left=20] (de);
            \path (de) edge[->, bend left=20] (ev);
            \path (ev) edge[->, bend left=20] (pr);
            \path (pr) edge[->, bend left=20] (an);
            \path (ev) edge[->] (im);
        \end{scope}

        \begin{pgfonlayer}{background}
            \filldraw [line width=4mm,join=round,black!10]
            (de.north  -| id.west) rectangle (pr.south  -| im.east);
        \end{pgfonlayer}
    \end{tikzpicture}
    \caption{Interaction Design Process; based on Figure 4.1 of Dix et al., 2004}
    \label{fig:idpdiagram}
\end{figure}

\begin{quote}
\textbf{Requirements:} The first stage is establishing what exactly is needed. As a pioneering study in this field it is necessary to find out what is currently happening. For example, how do speech disabled individuals currently interact in public using sign language? How does the process of communication work? 
A number of techniques have been documented to be used for this in HCI \parencite{Dix2004}  \parencite{Zimmerman:2007:RTD:1240624.1240704} like interviews, video documentation and direct observation.
 
\textbf{Analysis:} Observation and interview are analysed to highlight how people carry out various tasks in relation to the problem identified. The results are classified in a format to outline key issues resulting in task models. Task analysis methods are then developed and applied to formulate a proposal for a design solution. 

\textbf{Design:} Design is at the core of the interaction design process. This phase starts with the data gathered from previous steps and moves from what we need to design, to how we should design. Design loops are then attempted based on user testing and feedback, in compliance with user-centred design principles. 

\textbf{Iteration and prototyping:} Evaluation of prototypes will be based on usability testing feedback. Observations will be made in terms of performance and improvement areas. Most user interface designs involve some form of prototyping, producing early versions of systems to try out with real users \parencite{Bevan1999}. This is my approach for the proposed data glove design. Prototyping iteration will be discussed in more detail in evaluation methods. 

\textbf{Implementation and deployment:} Finally, when the design gives indications that is successful based on user feedback from testing rounds, the plan is to create it and deploy it. This will involve finalising writing code, concluding hardware design, writing documentation and manuals - everything that goes into a real system that can be given to others in preparation for production. 
\end{quote}

\section{Evaluation Methods}

Evaluation methods will be divided into two overlapping sets \parencite{Fallman2005}:

\begin{enumerate}
    \item Full-scale evaluation studies
    \item Formative evaluation and iterative testing
\end{enumerate}

\subsection{Full-Scale Evaluation Studies} 

HCI studies have used full scale evaluation to compare the performance of different systems \parencite{Wania2006}. Full scale evaluations are also known to have been used to examine specific features of existing systems for the purpose of further development. In full scale evaluation studies  ``A group of representative subjects are recruited to learn and use each of the systems and compare them on a pertinent set of performance measures'' \parencite{Cox2008}.

For my proposed data glove prototypes, I will conduct a series of in-depth longitudinal case studies with two groups of users: adults with speech disabilities and children with non-verbal autism. The aim of the studies is to know what will happen to real users over the period of time they will actually use my proposed design of the data glove. These studies will only be feasible by doing direct experiments with real users participating on a full time basis for six months in each comparison group. There are several points to consider for the testing rounds:

\begin{itemize}
    \item Due to the nature of the participants' disabilities, it is not feasible to conduct studies in a group setting or with big numbers of participants.
    \item One-on-one time will be needed with study participants to train them on how to use the new technology, keeping in mind that disabilities will vary between users. 
    \item It is common for testing with participants who have disabilities to gain feedback through a care giver, a therapist or a family member \parencite{Lazar2010}
\end{itemize}

Evaluation criteria will be classified under two main categories:
Performance Metrics: Isolating performance features and setting them as evaluation criteria is key to identifying why a system works better than another. One proposal \parencite{Roberts1983} is to use a set of "benchmark" tests that are chosen to represent the important functions performed with a system.

Usability issues: In users’ feedback I will be keen to observe and discover possible trouble-spots in the use of the prototypes, so that solutions can be proposed in the next cycle of prototype design \parencite{Klasnja2011}. To be valuable, evaluations of this kind must look at the details of use (time, errors, user reactions) for isolated functions rather than overall performance. Lessons learned from such studies provide important foundation for the development of future systems designs \parencite{Cox2008}.

\subsection{Formative Evaluation and Iterative Testing}
\label{chap:iterativetesting}

Cost is a fundamental factor in this research. Therefore, it is important to justify why I intend to conduct multiple rounds of prototype building and testing. Designing multiple prototypes each performing an isolated task and testing this particular feature is more effective than prototyping a fully executed system and testing multiple features at once. ``The best strategy for good design is to try various options (suggested, of course, by experience with previous similar systems, guidelines, and available principles), test them, and be guided by the failures, successes and comments garnered in watching their use, redesign trying new options, and iterate. This is called formative evaluation or developmental evaluation. The idea is simple enough. The barriers to its more frequent use are largely lack of will (organizational resistance), lack of time, or lack of ingenuity'' \parencite{Dix2004}. 

It is documented in previous HCI research \parencite{Cox2008} \parencite{Lazar2010} that formative testing can be both extremely effective and quite economical. Although a single test is not sufficient, multiple iterations of the whole system are not required to evaluate it. ``There are many reports in the literature, of dramatic improvements in usability in cases where two or three iterations were made on each important interface design problem, each requiring about a dozen hours of human testing and an equivalent amount of reprogramming'' \parencite{Georges2004}.

HCI researchers \parencite{Cox2008} \parencite{Lazar2010} have strongly recommended that user testing begin as early in the development cycle as possible, so that improvements can be made before design processes and coding become complex. For this to become feasible, it is advised to keep the system development flexible and easily modified to be able to conduct continuous user-testing. This is known as ``rapid prototyping, and consists of first developing a system specifically designed to be easily modifiable'' \parencite{Wania2006}. This is done through segmenting performance and postponing the launch of the full system to a later stage in the study \parencite{Dix2004} \parencite{Georges2004}.

An exemplary case study and rational account of the iterative testing and rapid prototyping approach is given in an article by Good et al. \parencite{Cox2008} in which they describe the process as ``User derived interface design.''

\begin{figure} 
    \centering
    \begin{tikzpicture}[node distance=1em, >=stealth', bend angle=45, auto, every node/.style={scale=0.7}]
    
    \tikzstyle{place}=[rectangle, rounded corners, thick, draw=blue!22, fill=blue!20, minimum width=5em]
    
    \tikzstyle{every label}=[red]
    
    \begin{scope}
    \node [place] (id)                              {Identify a Problem};
    \node [place] (an) [right=of id]                {Analysis};
    \node [place] (pr) [below=of de, yshift=-3em]       {Prototype};
    \node [place] (ev) [right=of de, yshift=-3em]                   {Test \& Evaluate};
    \node [place] (im) [right=of ev]                {Implement \& Deploy};
    
    \path (id) edge[->] (an);
    \path (an) edge[->, bend left=40] (ev);
    \path (ev) edge[->, bend left=20] (pr);
    \path (pr) edge[->, bend left=20] (an);
    \path (ev) edge[->] (im);
    \end{scope}
    
    \begin{pgfonlayer}{background}
    \filldraw [line width=4mm,join=round,black!10]
    (de.north  -| id.west) rectangle (pr.south  -| im.east);
    \end{pgfonlayer}
    \end{tikzpicture}
    \caption{Iterative Prototyping; based on Figure 4.2 of Dix et al., 2004}
    \label{fig:idpdiagram2}
\end{figure}

In this way, a series of prototypes of the data glove will be designed and a chapter will be dedicated to prototyping: design and programming, following the same structure illustrated in figure 2. First prototype will be a proof of concept, to prove that the system works with minimal hardware and software. Testing will be conducted and feedback will be fed back into the design loop of the next prototype. The consequent prototypes’ features will be upgraded gradually based on usability testing, always considering the four main elements of this research: affordable, accessible, universal and most importantly effective in facilitating daily communication between speech disabled individuals and the public. 

As an example, in designing an interface for a prototype voice store and forward system, a first attempt-by an expert human factors team at a set of user procedures produced around 50\% unrecoverable errors in attempts to use the service. After four weeks of testing and three revisions in the protocol, field tests found the procedure to result in less than one error for every hundred uses\footnote{Riley, cited \parencite{Cox2008}}. The voice message system demonstrated by IBM at the 1984 Olympics in Los Angeles\footnote{Gould and Boise, cited \parencite{Cox2008}} was developed by a team of programmers and behavioural scientists who continuously tried new versions of the system and its protocol and made revisions for several months. Despite what would ordinarily be considered a rather small-scale development effort, usability in the initial full-scale trial was extraordinarily good. The development of the much acclaimed user interface for the Apple Lisa computer (including design lessons later incorporated into the MacIntosh) was accomplished by almost continuous formative testing during system and interface development. In this case the testing was done by the manager of the interface programming group himself\footnote{Tesler, cited \parencite{Cox2008}}. The tests were relatively informal. Tesler selected a particular issue, for example where to put an "exit" icon on the screen, for semi-formal evaluation, (i.e. for some subjects it was in one place and for others in another), for each small experiment. Then he would have a handful of subjects try each of the two options. Most of the gain was not, however, from the comparison of the options but merely from observing the difficulties experienced by the users, and from the participants' comments and suggestions. According to Tesler the formal comparison served primarily to help in the discipline of systematizing observations. Difficulties were then either taken back to the design team for immediate alterations and retest, placed on a wish list for later solution, or ignored for practical reasons. Iterating this step every time an interesting design question arose, and after every significant milestone in the interface development, required running only about two dozen subjects per week through trials of the system, and caused almost no delay in the total development process since the fixes were made concurrently with the normal course of programming. This whole procedure strikes me as exemplary, as do the somewhat more elaborate and ingenious techniques utilized by Gould, Boies, Levy, Richards and Schoonard \parencite{Cox2008}.

\section{Case Studies - Literature Relating to Chosen Methods}

This research is user-centred. It is therefore based entirely on case studies. It is important to highlight the goals of HCI case studies \parencite{Lazar2010} \parencite{Cox2008} and the role they play feeding straight into interaction design research:

\begin{itemize}
    \item \textbf{Exploration:} Case studies provide valuable feedback in understanding novel problems especially in the early phases of the research.  Results often set the foundation for further investigation to inform new system design.
    
    \item \textbf{Explanation:} Case studies of tools are used to understand a context of the proposed technology.  It is very common in computer systems that study participants use the technology in unexpected ways that were not considered in the initial design which impacts the iterative design loop \parencite{Klasnja2011}.
    
    ``As HCI researchers often use a case study as a tool for understanding the technology usage and needs of populations of potential users, HCI case studies often largely draw upon representative users and use cases, omitting extreme cases.'' \parencite{Lazar2010}
    
    \item \textbf{Description:} Descriptive case studies are longitudinal and in-depth case studies.  They contribute to documenting a system, a context of technology use, and the process that led to a proposed design. They are particularly useful for technology involving new design methodologies. In interaction  research, the process behind the design is usually the focus of the case study.  ``Case studies that describe design processes and results have been written for a wide variety of topics in HCI, specifically for participants with impairments.'' \parencite{Lazar2010}  \parencite{Cox2008}.
    
    \item \textbf{Demonstration:} Demonstrative case studies are shorter and less in-depth than descriptive case studies.  Their purpose is to show how a new tool was successfully used.  Participants demonstrate the effective use of a new tool to complete one or more assigned tasks. 
\end{itemize}   

Case studies in this research will be of two types: Demonstration case studies followed by descriptive longitudinal and in-depth case studies.

\subsection{Demonstrative Case Study}

A good example is a case study conducted by Shinohara and Tenenberg \parencite{Shinohara2009} of a blind person’s (Sara) use of assistive technology. Sara’s case study focused on one person’s use of technology. How a blind person might use a variety of assistive technologies to achieve tasks, user interactions, including failures and response to those failures.

In this case study, Shinohara and Tenenberg \parencite{Shinohara2009} used three types of technology biography\footnote{Blyth and Mon and Park, cited \parencite{Cox2008}}: ``demonstrations of devices (technology tours), reflections on memories of early use of and reactions to devices(personal histories), and wishful thinking about possible technological innovations (guided speculation)'' \parencite{Shinohara2009}. Data sources used in this study demonstrate three types of case study data: ``artefacts, observation, and interviews'' \parencite{Shinohara2009}.

A total of 12 hours was recorded in Sara’s home, broken down into six, two hour sessions.  Raw data consisted of written notes, audio recordings, interviews and photo documentation.  Twelve tasks were defined and recorded in terms of their goals.  The insights from the individual tasks guided the design of improved tools \parencite{Shinohara2009}.

Although Sara does not provide a comprehensive picture of the needs and concerns of all blind people, the investigations of her needs and goals led to valuable insights that might apply to many other blind people.  The Shinohara and Tenenberg \parencite{Shinohara2009} case study helped the researchers to understand how Sara used a variety of technologies to accomplish multiple tasks.  They were specifically interested in understanding ``what technologies were most valued and used, when they were used and for what purpose'' \parencite{Shinohara2009}. Conducting the study in Sara’s home helped the investigators gain insights into how she actually addressed real challenges, as opposed to the more engineered results that might have been seen in the lab.

Sara’s case study demonstrates four key aspects used to describe case studies for users with impairments.  These points align with my research methods and will be followed as guidelines in the case studies of my research:

\begin{itemize}
    \item In-depth investigation of a small number of cases: In-depth, broad examinations of a small number of cases are used to address a vast range of concerns.
    
    \item Examination in context: Labs have the advantage of removing undesired external influences which is not a realistic or credible environment to show how the technology would work. On the other hand, single case studies conducted in a realistic context give meaningful results which are applicable in the real world and are more informative than large scale case studies conducted in a lab.
    
    \item Multiple data sources: Known as data triangulation and is especially important in single case studies. Multiple data sources are combined to validate the evidence and the quality of the data. Contradictions are important too because they compel the researcher to dig deeper, consulting new data sources, which is the essence of grounded theory and action research.
    
    \item Emphasis on qualitative data and analysis: Question of how the technology was used to achieve an assigned task are more important than how long it took to complete it. Researchers focus on the quality of the system in successfully delivering what is was designed for rather than the system speed. 
\end{itemize}

It is important to highlight that although single case studies can be very informative about the success of a system, results cannot be generalized to include all members of user criteria especially in disability. The real value of single case studies lie in creating realistic insights into design challenges which can be applied to a broader scale of users.

``Sara’s case study led to some suggestions for the design of assistive devices that would help Sara with her daily challenges, but could go further, to influence insights that apply to many blind people.  As a result, designs might be useful to a much broader range of blind users.'' \parencite{Shinohara2009}

The goal of Sara’s case study was: a deeper understanding of a blind user’s use of assistive technology in her home.  Similarly, usability case studies in this research will have a centre goal of understanding speech disabled participants’ use of the data glove and how effective it is in facilitating their daily communication and interaction within a public setup. 

\subsection{Descriptive Longitudinal and In-Depth Case Study}

In depth case studies executed in-context, in realistic environments, present credible and valuable evidence.  Careful consideration is given to the selection criteria of case study participants. Analyzing the data from the case studies and further interpretation is of the upmost importance\footnote{Yin, cited  \parencite{Lazar2010}}.

In these studies, the process of developing a new system or interaction technique is more important than the end product, especially for innovations that tackle new challenges in the context of use \parencite{Cohene2007}. 

A study at the University of Toronto \parencite{Cohene2007} provided the base for a very interesting single in-depth case study involving the design of an assistive technology tool to help people with Alzheimer’s disease. ``This project was based in a body of prior work that firmly established the importance of reminiscences for people with Alzheimer’s disease.'' \parencite{Cohene2007} The goal of the case study was to develop a multimedia tool to help people with Alzheimer’s disease recall and relive old memories. The sole participant of the case study was a 91 year old woman named Laura. Laura and her two daughters were fundamental in the study which focused on developing a system to help Laura with her memory \parencite{Cohene2007}. 

The study started with an exploratory phase to understand Alzheimer’s disease challenges faced by patients and their families. A broad understating of the disease was necessary even though the study was aimed to develop a tool specifically tailored to the needs and abilities of Laura.  Researchers’ observations resulted in a comprehensive understanding of the ``abilities and impairments of the participants, leading to a set of design principles'' \parencite{Cohene2007}. The study also included feedback from caretakers and therapists which acted as a basis in outlining a set of guidelines to assist with memory recollection. As part of the study, family members were required to complete a ``family workbook'' accumulating stories in the form of pictures, videos and music.  The collected media was to be included in the tool the researchers were working on developing, with the main purpose of helping the study participants with Alzheimer’s disease remember.   
The tool was developed through a series of prototypes which lead to an interactive multimedia device informed by the system whit output displayed on a screen.  The prototypes were refined based on the feedback of the study participants during eight testing sessions over a period of four weeks \parencite{Cohene2007}. 

The research team conducted follow-up interviews with family members which confirmed that the system contributed in enhancing the memory of the participants. 

``This project as a whole is an exploratory case study. As relatively little work has been done on user interfaces for people with Alzheimer’s disease, the description of a successful process is valuable in and of itself'' \parencite{Cohene2007}. The proposed design served to generate further investigations rather than as a solution.

It is very hard to generalize when it comes to disability and especially a cognitive one like Alzheimer’s disease. Researchers on this case study aimed at extending the applicability of this work by scaling the design process to include more participants to improve the tool \parencite{Cohene2007}.

This research required serious time commitment from all parties involved: participants with Alzheimer’s disease, their family members, and research team members. This, combined with the emotional strain, required intensive resources.  Even though the result could not be generalized to other users, the documentation of the design process and the resulting designed tool were considered important contributions \parencite{Cohene2007}.

\begin{quote}
    ``The most broadly applicable results from this story lie in the lessons learned. The authors concluded that new design methods and principles were needed for working with individuals with Alzheimer's disease, that active participation was more stimulating than passive, and that working with both the patients and their family members throughout the entire design process was necessary. Practical concerns included the resource-intensive nature of the research, the emotional commitment required of the family members, the need to make the approach practical for larger numbers of families, and the need for standards for evaluation'' \parencite{Cohene2007}.
\end{quote}

Although drawn from this particular project, these insights might be extremely valuable to others interested in conducting related research.
Similar to this study, my research will require working directly with speech disabled participants and children with non-verbal autism.  My research dictates interacting with family members, therapists and caregivers of case study participants.  Also, through the process of testing and collecting information, I can learn a lot about the nature of the disability and how my design of an assistive tool can help not only the participants but also the broad spectrum of users with similar disabilities making my design proposal universal and accessible to many people.
